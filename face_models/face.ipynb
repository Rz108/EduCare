{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Face Stress detection__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization,AveragePooling2D\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('fer2013.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 35887 entries, 0 to 35886\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   emotion  35887 non-null  int64 \n",
      " 1   pixels   35887 non-null  object\n",
      " 2   Usage    35887 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 841.2+ KB\n",
      "None\n",
      "Usage\n",
      "Training       28709\n",
      "PublicTest      3589\n",
      "PrivateTest     3589\n",
      "Name: count, dtype: int64\n",
      "   emotion                                             pixels     Usage\n",
      "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
      "1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
      "2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
      "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
      "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training\n"
     ]
    }
   ],
   "source": [
    "print(df.info())\n",
    "print(df[\"Usage\"].value_counts())\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,train_y,X_test,test_y=[],[],[],[]\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    val=row['pixels'].split(\" \")\n",
    "    try:\n",
    "        if 'Training' in row['Usage']:\n",
    "           X_train.append(np.array(val,'float32'))\n",
    "           train_y.append(row['emotion'])\n",
    "        elif 'PublicTest' in row['Usage']:\n",
    "           X_test.append(np.array(val,'float32'))\n",
    "           test_y.append(row['emotion'])\n",
    "    except:\n",
    "        print(f\"error occured at index :{index} and row:{row}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "449/449 [==============================] - 7s 15ms/step - loss: 1.7387 - accuracy: 0.2850 - val_loss: 1.5909 - val_accuracy: 0.3795\n",
      "Epoch 2/200\n",
      "449/449 [==============================] - 7s 16ms/step - loss: 1.5138 - accuracy: 0.4058 - val_loss: 1.4023 - val_accuracy: 0.4539\n",
      "Epoch 3/200\n",
      "449/449 [==============================] - 7s 16ms/step - loss: 1.4024 - accuracy: 0.4560 - val_loss: 1.3207 - val_accuracy: 0.4870\n",
      "Epoch 4/200\n",
      "449/449 [==============================] - 7s 16ms/step - loss: 1.3389 - accuracy: 0.4817 - val_loss: 1.2853 - val_accuracy: 0.5065\n",
      "Epoch 5/200\n",
      "449/449 [==============================] - 7s 16ms/step - loss: 1.2887 - accuracy: 0.5037 - val_loss: 1.2427 - val_accuracy: 0.5149\n",
      "Epoch 6/200\n",
      "449/449 [==============================] - 7s 16ms/step - loss: 1.2617 - accuracy: 0.5156 - val_loss: 1.2351 - val_accuracy: 0.5194\n",
      "Epoch 7/200\n",
      "449/449 [==============================] - 7s 16ms/step - loss: 1.2285 - accuracy: 0.5293 - val_loss: 1.2255 - val_accuracy: 0.5266\n",
      "Epoch 8/200\n",
      "449/449 [==============================] - 7s 16ms/step - loss: 1.2016 - accuracy: 0.5431 - val_loss: 1.2322 - val_accuracy: 0.5208\n",
      "Epoch 9/200\n",
      "449/449 [==============================] - 7s 16ms/step - loss: 1.1835 - accuracy: 0.5477 - val_loss: 1.2043 - val_accuracy: 0.5442\n",
      "Epoch 10/200\n",
      "449/449 [==============================] - 7s 16ms/step - loss: 1.1594 - accuracy: 0.5535 - val_loss: 1.1657 - val_accuracy: 0.5511\n",
      "Epoch 11/200\n",
      "449/449 [==============================] - 7s 16ms/step - loss: 1.1454 - accuracy: 0.5585 - val_loss: 1.1883 - val_accuracy: 0.5486\n",
      "Epoch 12/200\n",
      "449/449 [==============================] - 7s 16ms/step - loss: 1.1225 - accuracy: 0.5707 - val_loss: 1.1625 - val_accuracy: 0.5609\n",
      "Epoch 13/200\n",
      "449/449 [==============================] - 7s 16ms/step - loss: 1.1026 - accuracy: 0.5782 - val_loss: 1.1616 - val_accuracy: 0.5528\n",
      "Epoch 14/200\n",
      "449/449 [==============================] - 7s 16ms/step - loss: 1.0863 - accuracy: 0.5868 - val_loss: 1.1672 - val_accuracy: 0.5575\n",
      "Epoch 15/200\n",
      "449/449 [==============================] - 7s 15ms/step - loss: 1.0657 - accuracy: 0.5920 - val_loss: 1.1820 - val_accuracy: 0.5506\n",
      "Epoch 16/200\n",
      "449/449 [==============================] - 7s 16ms/step - loss: 1.0540 - accuracy: 0.5958 - val_loss: 1.1569 - val_accuracy: 0.5612\n",
      "Epoch 17/200\n",
      "449/449 [==============================] - 7s 16ms/step - loss: 1.0368 - accuracy: 0.6046 - val_loss: 1.1630 - val_accuracy: 0.5620\n",
      "Epoch 18/200\n",
      "449/449 [==============================] - 7s 16ms/step - loss: 1.0196 - accuracy: 0.6105 - val_loss: 1.1761 - val_accuracy: 0.5673\n",
      "Epoch 19/200\n",
      "449/449 [==============================] - 7s 16ms/step - loss: 1.0082 - accuracy: 0.6166 - val_loss: 1.1727 - val_accuracy: 0.5612\n",
      "Epoch 20/200\n",
      "449/449 [==============================] - 7s 15ms/step - loss: 0.9893 - accuracy: 0.6217 - val_loss: 1.1948 - val_accuracy: 0.5659\n",
      "Epoch 21/200\n",
      "449/449 [==============================] - 7s 16ms/step - loss: 0.9706 - accuracy: 0.6291 - val_loss: 1.1847 - val_accuracy: 0.5701\n",
      "Epoch 22/200\n",
      "449/449 [==============================] - 7s 15ms/step - loss: 0.9629 - accuracy: 0.6323 - val_loss: 1.1761 - val_accuracy: 0.5553\n",
      "Epoch 23/200\n",
      "449/449 [==============================] - 7s 15ms/step - loss: 0.9420 - accuracy: 0.6413 - val_loss: 1.1895 - val_accuracy: 0.5567\n",
      "Epoch 24/200\n",
      "449/449 [==============================] - 7s 15ms/step - loss: 0.9260 - accuracy: 0.6462 - val_loss: 1.1845 - val_accuracy: 0.5726\n",
      "Epoch 25/200\n",
      "449/449 [==============================] - 7s 15ms/step - loss: 0.9129 - accuracy: 0.6516 - val_loss: 1.1950 - val_accuracy: 0.5561\n",
      "Epoch 26/200\n",
      "449/449 [==============================] - 7s 15ms/step - loss: 0.9065 - accuracy: 0.6548 - val_loss: 1.2187 - val_accuracy: 0.5575\n",
      "Epoch 27/200\n",
      "449/449 [==============================] - 7s 15ms/step - loss: 0.8865 - accuracy: 0.6623 - val_loss: 1.2120 - val_accuracy: 0.5662\n",
      "Epoch 28/200\n",
      "449/449 [==============================] - 7s 15ms/step - loss: 0.8739 - accuracy: 0.6657 - val_loss: 1.2250 - val_accuracy: 0.5659\n",
      "Epoch 29/200\n",
      "449/449 [==============================] - 7s 15ms/step - loss: 0.8634 - accuracy: 0.6723 - val_loss: 1.2016 - val_accuracy: 0.5745\n",
      "Epoch 30/200\n",
      "449/449 [==============================] - 7s 15ms/step - loss: 0.8438 - accuracy: 0.6787 - val_loss: 1.2553 - val_accuracy: 0.5645\n",
      "Epoch 31/200\n",
      "449/449 [==============================] - 7s 15ms/step - loss: 0.8375 - accuracy: 0.6805 - val_loss: 1.2322 - val_accuracy: 0.5770\n",
      "Epoch 32/200\n",
      "449/449 [==============================] - 7s 15ms/step - loss: 0.8227 - accuracy: 0.6914 - val_loss: 1.2441 - val_accuracy: 0.5756\n",
      "Epoch 33/200\n",
      "449/449 [==============================] - 7s 15ms/step - loss: 0.8024 - accuracy: 0.6985 - val_loss: 1.2699 - val_accuracy: 0.5614\n",
      "Epoch 34/200\n",
      "449/449 [==============================] - 7s 16ms/step - loss: 0.7980 - accuracy: 0.7000 - val_loss: 1.2636 - val_accuracy: 0.5765\n",
      "Epoch 35/200\n",
      "449/449 [==============================] - 7s 15ms/step - loss: 0.7816 - accuracy: 0.7092 - val_loss: 1.2736 - val_accuracy: 0.5659\n",
      "Epoch 36/200\n",
      "449/449 [==============================] - 7s 15ms/step - loss: 0.7712 - accuracy: 0.7105 - val_loss: 1.2743 - val_accuracy: 0.5684\n",
      "Epoch 37/200\n",
      "449/449 [==============================] - 7s 16ms/step - loss: 0.7674 - accuracy: 0.7099 - val_loss: 1.3284 - val_accuracy: 0.5709\n",
      "Epoch 38/200\n",
      "449/449 [==============================] - 7s 15ms/step - loss: 0.7525 - accuracy: 0.7164 - val_loss: 1.2675 - val_accuracy: 0.5628\n",
      "Epoch 39/200\n",
      "449/449 [==============================] - 7s 15ms/step - loss: 0.7421 - accuracy: 0.7227 - val_loss: 1.3115 - val_accuracy: 0.5745\n",
      "Epoch 40/200\n",
      "449/449 [==============================] - 7s 15ms/step - loss: 0.7294 - accuracy: 0.7259 - val_loss: 1.2950 - val_accuracy: 0.5704\n",
      "Epoch 41/200\n",
      "449/449 [==============================] - 7s 15ms/step - loss: 0.7249 - accuracy: 0.7274 - val_loss: 1.3224 - val_accuracy: 0.5648\n",
      "Epoch 42/200\n",
      "449/449 [==============================] - 7s 15ms/step - loss: 0.7124 - accuracy: 0.7351 - val_loss: 1.3093 - val_accuracy: 0.5729\n",
      "Epoch 43/200\n",
      "449/449 [==============================] - 7s 16ms/step - loss: 0.7085 - accuracy: 0.7359 - val_loss: 1.2906 - val_accuracy: 0.5651\n",
      "Epoch 44/200\n",
      "449/449 [==============================] - 7s 15ms/step - loss: 0.6926 - accuracy: 0.7393 - val_loss: 1.3319 - val_accuracy: 0.5676\n",
      "Epoch 45/200\n",
      "449/449 [==============================] - 7s 15ms/step - loss: 0.6853 - accuracy: 0.7411 - val_loss: 1.3444 - val_accuracy: 0.5603\n",
      "Epoch 46/200\n",
      "449/449 [==============================] - 7s 15ms/step - loss: 0.6720 - accuracy: 0.7516 - val_loss: 1.3374 - val_accuracy: 0.5712\n",
      "Epoch 47/200\n",
      "449/449 [==============================] - 7s 16ms/step - loss: 0.6611 - accuracy: 0.7547 - val_loss: 1.3693 - val_accuracy: 0.5701\n",
      "Epoch 48/200\n",
      "449/449 [==============================] - 7s 16ms/step - loss: 0.6603 - accuracy: 0.7545 - val_loss: 1.3281 - val_accuracy: 0.5584\n",
      "Epoch 49/200\n",
      "449/449 [==============================] - 7s 16ms/step - loss: 0.6505 - accuracy: 0.7614 - val_loss: 1.3601 - val_accuracy: 0.5606\n",
      "Epoch 50/200\n",
      "449/449 [==============================] - 7s 15ms/step - loss: 0.6302 - accuracy: 0.7643 - val_loss: 1.3694 - val_accuracy: 0.5687\n",
      "Epoch 51/200\n",
      "449/449 [==============================] - 7s 15ms/step - loss: 0.6353 - accuracy: 0.7646 - val_loss: 1.3525 - val_accuracy: 0.5726\n",
      "Epoch 52/200\n",
      "449/449 [==============================] - 7s 16ms/step - loss: 0.6247 - accuracy: 0.7663 - val_loss: 1.3954 - val_accuracy: 0.5745\n",
      "Epoch 53/200\n",
      "449/449 [==============================] - 7s 16ms/step - loss: 0.6181 - accuracy: 0.7712 - val_loss: 1.4131 - val_accuracy: 0.5776\n",
      "Epoch 54/200\n",
      "449/449 [==============================] - 7s 16ms/step - loss: 0.6102 - accuracy: 0.7740 - val_loss: 1.3913 - val_accuracy: 0.5737\n",
      "Epoch 55/200\n",
      "449/449 [==============================] - 7s 16ms/step - loss: 0.6147 - accuracy: 0.7738 - val_loss: 1.3895 - val_accuracy: 0.5776\n",
      "Epoch 56/200\n",
      "449/449 [==============================] - 7s 16ms/step - loss: 0.6046 - accuracy: 0.7758 - val_loss: 1.3981 - val_accuracy: 0.5726\n",
      "Epoch 57/200\n",
      "449/449 [==============================] - 7s 16ms/step - loss: 0.5876 - accuracy: 0.7840 - val_loss: 1.4736 - val_accuracy: 0.5701\n",
      "Epoch 58/200\n",
      "449/449 [==============================] - 7s 16ms/step - loss: 0.5861 - accuracy: 0.7850 - val_loss: 1.4260 - val_accuracy: 0.5715\n",
      "Epoch 59/200\n",
      "449/449 [==============================] - 12s 27ms/step - loss: 0.5904 - accuracy: 0.7818 - val_loss: 1.4219 - val_accuracy: 0.5801\n",
      "Epoch 60/200\n",
      "449/449 [==============================] - 11s 24ms/step - loss: 0.5694 - accuracy: 0.7927 - val_loss: 1.4667 - val_accuracy: 0.5715\n",
      "Epoch 61/200\n",
      "449/449 [==============================] - 11s 24ms/step - loss: 0.5645 - accuracy: 0.7892 - val_loss: 1.4452 - val_accuracy: 0.5712\n",
      "Epoch 62/200\n",
      "449/449 [==============================] - 11s 24ms/step - loss: 0.5676 - accuracy: 0.7941 - val_loss: 1.4621 - val_accuracy: 0.5681\n",
      "Epoch 63/200\n",
      "449/449 [==============================] - 10s 22ms/step - loss: 0.5547 - accuracy: 0.7968 - val_loss: 1.4822 - val_accuracy: 0.5637\n",
      "Epoch 64/200\n",
      "449/449 [==============================] - 12s 26ms/step - loss: 0.5575 - accuracy: 0.7978 - val_loss: 1.4747 - val_accuracy: 0.5737\n",
      "Epoch 65/200\n",
      "449/449 [==============================] - 10s 22ms/step - loss: 0.5496 - accuracy: 0.7986 - val_loss: 1.4934 - val_accuracy: 0.5720\n",
      "Epoch 66/200\n",
      "449/449 [==============================] - 11s 25ms/step - loss: 0.5417 - accuracy: 0.8013 - val_loss: 1.4567 - val_accuracy: 0.5862\n",
      "Epoch 67/200\n",
      "449/449 [==============================] - 12s 28ms/step - loss: 0.5329 - accuracy: 0.8053 - val_loss: 1.5267 - val_accuracy: 0.5578\n",
      "Epoch 68/200\n",
      "449/449 [==============================] - 10s 23ms/step - loss: 0.5280 - accuracy: 0.8073 - val_loss: 1.4968 - val_accuracy: 0.5676\n",
      "Epoch 69/200\n",
      "449/449 [==============================] - 10s 22ms/step - loss: 0.5170 - accuracy: 0.8155 - val_loss: 1.5789 - val_accuracy: 0.5698\n",
      "Epoch 70/200\n",
      "449/449 [==============================] - 10s 23ms/step - loss: 0.5144 - accuracy: 0.8139 - val_loss: 1.4823 - val_accuracy: 0.5673\n",
      "Epoch 71/200\n",
      "449/449 [==============================] - 11s 24ms/step - loss: 0.5120 - accuracy: 0.8146 - val_loss: 1.4583 - val_accuracy: 0.5734\n",
      "Epoch 72/200\n",
      "449/449 [==============================] - 10s 23ms/step - loss: 0.5062 - accuracy: 0.8172 - val_loss: 1.4987 - val_accuracy: 0.5659\n",
      "Epoch 73/200\n",
      "449/449 [==============================] - 11s 24ms/step - loss: 0.5019 - accuracy: 0.8223 - val_loss: 1.4990 - val_accuracy: 0.5770\n",
      "Epoch 74/200\n",
      "449/449 [==============================] - 10s 23ms/step - loss: 0.5066 - accuracy: 0.8172 - val_loss: 1.5204 - val_accuracy: 0.5731\n",
      "Epoch 75/200\n",
      "449/449 [==============================] - 10s 23ms/step - loss: 0.5025 - accuracy: 0.8157 - val_loss: 1.5771 - val_accuracy: 0.5715\n",
      "Epoch 76/200\n",
      "449/449 [==============================] - 11s 24ms/step - loss: 0.5019 - accuracy: 0.8196 - val_loss: 1.4721 - val_accuracy: 0.5826\n",
      "Epoch 77/200\n",
      "449/449 [==============================] - 11s 24ms/step - loss: 0.4847 - accuracy: 0.8277 - val_loss: 1.5446 - val_accuracy: 0.5665\n",
      "Epoch 78/200\n",
      "449/449 [==============================] - 10s 21ms/step - loss: 0.4890 - accuracy: 0.8239 - val_loss: 1.5425 - val_accuracy: 0.5745\n",
      "Epoch 79/200\n",
      "449/449 [==============================] - 10s 23ms/step - loss: 0.4704 - accuracy: 0.8298 - val_loss: 1.5910 - val_accuracy: 0.5589\n",
      "Epoch 80/200\n",
      "449/449 [==============================] - 10s 23ms/step - loss: 0.4761 - accuracy: 0.8268 - val_loss: 1.5688 - val_accuracy: 0.5709\n",
      "Epoch 81/200\n",
      "449/449 [==============================] - 11s 25ms/step - loss: 0.4741 - accuracy: 0.8278 - val_loss: 1.5441 - val_accuracy: 0.5737\n",
      "Epoch 82/200\n",
      "449/449 [==============================] - 10s 23ms/step - loss: 0.4756 - accuracy: 0.8304 - val_loss: 1.5958 - val_accuracy: 0.5667\n",
      "Epoch 83/200\n",
      "449/449 [==============================] - 10s 23ms/step - loss: 0.4678 - accuracy: 0.8320 - val_loss: 1.4735 - val_accuracy: 0.5745\n",
      "Epoch 84/200\n",
      "449/449 [==============================] - 10s 22ms/step - loss: 0.4745 - accuracy: 0.8306 - val_loss: 1.5518 - val_accuracy: 0.5793\n",
      "Epoch 85/200\n",
      "449/449 [==============================] - 16s 36ms/step - loss: 0.4537 - accuracy: 0.8364 - val_loss: 1.5153 - val_accuracy: 0.5701\n",
      "Epoch 86/200\n",
      "449/449 [==============================] - 11s 24ms/step - loss: 0.4542 - accuracy: 0.8358 - val_loss: 1.5489 - val_accuracy: 0.5740\n",
      "Epoch 87/200\n",
      "449/449 [==============================] - 11s 24ms/step - loss: 0.4543 - accuracy: 0.8373 - val_loss: 1.5638 - val_accuracy: 0.5807\n",
      "Epoch 88/200\n",
      "449/449 [==============================] - 10s 23ms/step - loss: 0.4469 - accuracy: 0.8376 - val_loss: 1.6311 - val_accuracy: 0.5620\n",
      "Epoch 89/200\n",
      "449/449 [==============================] - 10s 23ms/step - loss: 0.4560 - accuracy: 0.8387 - val_loss: 1.5969 - val_accuracy: 0.5698\n",
      "Epoch 90/200\n",
      "449/449 [==============================] - 11s 24ms/step - loss: 0.4389 - accuracy: 0.8442 - val_loss: 1.6019 - val_accuracy: 0.5770\n",
      "Epoch 91/200\n",
      "449/449 [==============================] - 11s 24ms/step - loss: 0.4414 - accuracy: 0.8438 - val_loss: 1.6047 - val_accuracy: 0.5770\n",
      "Epoch 92/200\n",
      "449/449 [==============================] - 10s 23ms/step - loss: 0.4298 - accuracy: 0.8455 - val_loss: 1.6332 - val_accuracy: 0.5740\n",
      "Epoch 93/200\n",
      "449/449 [==============================] - 10s 23ms/step - loss: 0.4340 - accuracy: 0.8458 - val_loss: 1.6215 - val_accuracy: 0.5773\n",
      "Epoch 94/200\n",
      "449/449 [==============================] - 10s 23ms/step - loss: 0.4321 - accuracy: 0.8438 - val_loss: 1.6618 - val_accuracy: 0.5609\n",
      "Epoch 95/200\n",
      "449/449 [==============================] - 10s 23ms/step - loss: 0.4253 - accuracy: 0.8466 - val_loss: 1.6359 - val_accuracy: 0.5704\n",
      "Epoch 96/200\n",
      "449/449 [==============================] - 11s 23ms/step - loss: 0.4192 - accuracy: 0.8503 - val_loss: 1.6537 - val_accuracy: 0.5748\n",
      "Epoch 97/200\n",
      "449/449 [==============================] - 10s 23ms/step - loss: 0.4232 - accuracy: 0.8484 - val_loss: 1.6374 - val_accuracy: 0.5731\n",
      "Epoch 98/200\n",
      "449/449 [==============================] - 10s 23ms/step - loss: 0.4322 - accuracy: 0.8467 - val_loss: 1.5879 - val_accuracy: 0.5768\n",
      "Epoch 99/200\n",
      "449/449 [==============================] - 10s 23ms/step - loss: 0.4246 - accuracy: 0.8510 - val_loss: 1.6236 - val_accuracy: 0.5645\n",
      "Epoch 100/200\n",
      "449/449 [==============================] - 10s 23ms/step - loss: 0.4155 - accuracy: 0.8528 - val_loss: 1.6490 - val_accuracy: 0.5717\n",
      "Epoch 101/200\n",
      "449/449 [==============================] - 10s 23ms/step - loss: 0.4118 - accuracy: 0.8555 - val_loss: 1.6841 - val_accuracy: 0.5592\n",
      "Epoch 102/200\n",
      "449/449 [==============================] - 11s 24ms/step - loss: 0.4018 - accuracy: 0.8598 - val_loss: 1.6450 - val_accuracy: 0.5854\n",
      "Epoch 103/200\n",
      "449/449 [==============================] - 12s 26ms/step - loss: 0.4098 - accuracy: 0.8542 - val_loss: 1.7457 - val_accuracy: 0.5698\n",
      "Epoch 104/200\n",
      "449/449 [==============================] - 11s 24ms/step - loss: 0.4251 - accuracy: 0.8511 - val_loss: 1.6420 - val_accuracy: 0.5720\n",
      "Epoch 105/200\n",
      "449/449 [==============================] - 10s 23ms/step - loss: 0.3946 - accuracy: 0.8601 - val_loss: 1.7246 - val_accuracy: 0.5692\n",
      "Epoch 106/200\n",
      "449/449 [==============================] - 11s 25ms/step - loss: 0.4082 - accuracy: 0.8570 - val_loss: 1.6912 - val_accuracy: 0.5762\n",
      "Epoch 107/200\n",
      "449/449 [==============================] - 11s 25ms/step - loss: 0.4061 - accuracy: 0.8560 - val_loss: 1.6168 - val_accuracy: 0.5653\n",
      "Epoch 108/200\n",
      "449/449 [==============================] - 11s 24ms/step - loss: 0.3895 - accuracy: 0.8635 - val_loss: 1.6611 - val_accuracy: 0.5793\n",
      "Epoch 109/200\n",
      "449/449 [==============================] - 11s 25ms/step - loss: 0.3924 - accuracy: 0.8628 - val_loss: 1.6971 - val_accuracy: 0.5726\n",
      "Epoch 110/200\n",
      "449/449 [==============================] - 14s 31ms/step - loss: 0.3966 - accuracy: 0.8619 - val_loss: 1.6451 - val_accuracy: 0.5715\n",
      "Epoch 111/200\n",
      "449/449 [==============================] - 18s 41ms/step - loss: 0.3816 - accuracy: 0.8616 - val_loss: 1.7479 - val_accuracy: 0.5684\n",
      "Epoch 112/200\n",
      "449/449 [==============================] - 10s 22ms/step - loss: 0.3937 - accuracy: 0.8629 - val_loss: 1.6409 - val_accuracy: 0.5837\n",
      "Epoch 113/200\n",
      "449/449 [==============================] - 12s 27ms/step - loss: 0.3914 - accuracy: 0.8628 - val_loss: 1.7455 - val_accuracy: 0.5665\n",
      "Epoch 114/200\n",
      "449/449 [==============================] - 11s 25ms/step - loss: 0.3819 - accuracy: 0.8680 - val_loss: 1.7327 - val_accuracy: 0.5709\n",
      "Epoch 115/200\n",
      "449/449 [==============================] - 16s 36ms/step - loss: 0.3799 - accuracy: 0.8656 - val_loss: 1.6888 - val_accuracy: 0.5723\n",
      "Epoch 116/200\n",
      "449/449 [==============================] - 18s 39ms/step - loss: 0.3860 - accuracy: 0.8651 - val_loss: 1.6995 - val_accuracy: 0.5712\n",
      "Epoch 117/200\n",
      "449/449 [==============================] - 15s 33ms/step - loss: 0.3824 - accuracy: 0.8676 - val_loss: 1.7117 - val_accuracy: 0.5684\n",
      "Epoch 118/200\n",
      "449/449 [==============================] - 13s 29ms/step - loss: 0.3829 - accuracy: 0.8658 - val_loss: 1.7063 - val_accuracy: 0.5715\n",
      "Epoch 119/200\n",
      "449/449 [==============================] - 15s 34ms/step - loss: 0.3738 - accuracy: 0.8701 - val_loss: 1.6986 - val_accuracy: 0.5651\n",
      "Epoch 120/200\n",
      "449/449 [==============================] - 14s 31ms/step - loss: 0.3677 - accuracy: 0.8720 - val_loss: 1.7586 - val_accuracy: 0.5620\n",
      "Epoch 121/200\n",
      "449/449 [==============================] - 13s 28ms/step - loss: 0.3862 - accuracy: 0.8653 - val_loss: 1.7497 - val_accuracy: 0.5695\n",
      "Epoch 122/200\n",
      "449/449 [==============================] - 13s 28ms/step - loss: 0.3727 - accuracy: 0.8722 - val_loss: 1.7115 - val_accuracy: 0.5662\n",
      "Epoch 123/200\n",
      "449/449 [==============================] - 12s 28ms/step - loss: 0.3618 - accuracy: 0.8728 - val_loss: 1.7488 - val_accuracy: 0.5648\n",
      "Epoch 124/200\n",
      "449/449 [==============================] - 15s 33ms/step - loss: 0.3659 - accuracy: 0.8731 - val_loss: 1.7890 - val_accuracy: 0.5673\n",
      "Epoch 125/200\n",
      "449/449 [==============================] - 24s 54ms/step - loss: 0.3916 - accuracy: 0.8650 - val_loss: 1.7357 - val_accuracy: 0.5645\n",
      "Epoch 126/200\n",
      "449/449 [==============================] - 24s 54ms/step - loss: 0.3592 - accuracy: 0.8764 - val_loss: 1.8165 - val_accuracy: 0.5695\n",
      "Epoch 127/200\n",
      "449/449 [==============================] - 25s 56ms/step - loss: 0.3680 - accuracy: 0.8755 - val_loss: 1.7320 - val_accuracy: 0.5709\n",
      "Epoch 128/200\n",
      "449/449 [==============================] - 27s 59ms/step - loss: 0.3559 - accuracy: 0.8763 - val_loss: 1.8381 - val_accuracy: 0.5706\n",
      "Epoch 129/200\n",
      "449/449 [==============================] - 19s 43ms/step - loss: 0.3602 - accuracy: 0.8745 - val_loss: 1.7012 - val_accuracy: 0.5656\n",
      "Epoch 130/200\n",
      "449/449 [==============================] - 11s 24ms/step - loss: 0.3655 - accuracy: 0.8762 - val_loss: 1.7680 - val_accuracy: 0.5673\n",
      "Epoch 131/200\n",
      "449/449 [==============================] - 11s 24ms/step - loss: 0.3563 - accuracy: 0.8759 - val_loss: 1.7273 - val_accuracy: 0.5729\n",
      "Epoch 132/200\n",
      "449/449 [==============================] - 10s 21ms/step - loss: 0.3670 - accuracy: 0.8745 - val_loss: 1.7397 - val_accuracy: 0.5687\n",
      "Epoch 133/200\n",
      "449/449 [==============================] - 10s 22ms/step - loss: 0.3573 - accuracy: 0.8738 - val_loss: 1.8400 - val_accuracy: 0.5673\n",
      "Epoch 134/200\n",
      "449/449 [==============================] - 9s 20ms/step - loss: 0.3455 - accuracy: 0.8801 - val_loss: 1.7792 - val_accuracy: 0.5676\n",
      "Epoch 135/200\n",
      "449/449 [==============================] - 9s 20ms/step - loss: 0.3576 - accuracy: 0.8764 - val_loss: 1.7587 - val_accuracy: 0.5673\n",
      "Epoch 136/200\n",
      "449/449 [==============================] - 9s 20ms/step - loss: 0.3447 - accuracy: 0.8807 - val_loss: 1.9137 - val_accuracy: 0.5637\n",
      "Epoch 137/200\n",
      "449/449 [==============================] - 10s 21ms/step - loss: 0.3519 - accuracy: 0.8793 - val_loss: 1.8532 - val_accuracy: 0.5754\n",
      "Epoch 138/200\n",
      "449/449 [==============================] - 10s 22ms/step - loss: 0.3666 - accuracy: 0.8732 - val_loss: 1.7723 - val_accuracy: 0.5631\n",
      "Epoch 139/200\n",
      "449/449 [==============================] - 11s 25ms/step - loss: 0.3477 - accuracy: 0.8797 - val_loss: 1.8755 - val_accuracy: 0.5748\n",
      "Epoch 140/200\n",
      "449/449 [==============================] - 15s 33ms/step - loss: 0.3507 - accuracy: 0.8815 - val_loss: 1.7207 - val_accuracy: 0.5614\n",
      "Epoch 141/200\n",
      "449/449 [==============================] - 17s 37ms/step - loss: 0.3386 - accuracy: 0.8825 - val_loss: 1.7406 - val_accuracy: 0.5765\n",
      "Epoch 142/200\n",
      "449/449 [==============================] - 14s 30ms/step - loss: 0.3421 - accuracy: 0.8808 - val_loss: 1.7610 - val_accuracy: 0.5673\n",
      "Epoch 143/200\n",
      "449/449 [==============================] - 16s 35ms/step - loss: 0.3372 - accuracy: 0.8839 - val_loss: 1.8291 - val_accuracy: 0.5667\n",
      "Epoch 144/200\n",
      "449/449 [==============================] - 17s 37ms/step - loss: 0.3428 - accuracy: 0.8820 - val_loss: 1.8541 - val_accuracy: 0.5606\n",
      "Epoch 145/200\n",
      "449/449 [==============================] - 13s 29ms/step - loss: 0.3455 - accuracy: 0.8817 - val_loss: 1.8629 - val_accuracy: 0.5656\n",
      "Epoch 146/200\n",
      "449/449 [==============================] - 15s 34ms/step - loss: 0.3407 - accuracy: 0.8823 - val_loss: 1.8119 - val_accuracy: 0.5684\n",
      "Epoch 147/200\n",
      "449/449 [==============================] - 19s 43ms/step - loss: 0.3407 - accuracy: 0.8848 - val_loss: 1.7990 - val_accuracy: 0.5667\n",
      "Epoch 148/200\n",
      "449/449 [==============================] - 21s 46ms/step - loss: 0.3321 - accuracy: 0.8835 - val_loss: 1.8563 - val_accuracy: 0.5729\n",
      "Epoch 149/200\n",
      "449/449 [==============================] - 16s 36ms/step - loss: 0.3377 - accuracy: 0.8844 - val_loss: 1.8334 - val_accuracy: 0.5612\n",
      "Epoch 150/200\n",
      "449/449 [==============================] - 19s 43ms/step - loss: 0.3304 - accuracy: 0.8874 - val_loss: 1.8302 - val_accuracy: 0.5634\n",
      "Epoch 151/200\n",
      "449/449 [==============================] - 16s 35ms/step - loss: 0.3195 - accuracy: 0.8897 - val_loss: 1.7920 - val_accuracy: 0.5639\n",
      "Epoch 152/200\n",
      "449/449 [==============================] - 15s 33ms/step - loss: 0.3445 - accuracy: 0.8827 - val_loss: 1.8306 - val_accuracy: 0.5681\n",
      "Epoch 153/200\n",
      "449/449 [==============================] - 14s 32ms/step - loss: 0.3331 - accuracy: 0.8869 - val_loss: 1.8588 - val_accuracy: 0.5620\n",
      "Epoch 154/200\n",
      "449/449 [==============================] - 19s 41ms/step - loss: 0.3295 - accuracy: 0.8879 - val_loss: 1.8876 - val_accuracy: 0.5606\n",
      "Epoch 155/200\n",
      "449/449 [==============================] - 13s 28ms/step - loss: 0.3433 - accuracy: 0.8827 - val_loss: 1.8706 - val_accuracy: 0.5626\n",
      "Epoch 156/200\n",
      "449/449 [==============================] - 14s 31ms/step - loss: 0.3287 - accuracy: 0.8866 - val_loss: 1.8425 - val_accuracy: 0.5681\n",
      "Epoch 157/200\n",
      "449/449 [==============================] - 15s 33ms/step - loss: 0.3232 - accuracy: 0.8905 - val_loss: 1.8336 - val_accuracy: 0.5726\n",
      "Epoch 158/200\n",
      "449/449 [==============================] - 24s 54ms/step - loss: 0.3208 - accuracy: 0.8900 - val_loss: 1.8577 - val_accuracy: 0.5754\n",
      "Epoch 159/200\n",
      "449/449 [==============================] - 20s 44ms/step - loss: 0.3212 - accuracy: 0.8916 - val_loss: 1.8336 - val_accuracy: 0.5651\n",
      "Epoch 160/200\n",
      "449/449 [==============================] - 18s 40ms/step - loss: 0.3303 - accuracy: 0.8861 - val_loss: 1.8481 - val_accuracy: 0.5706\n",
      "Epoch 161/200\n",
      "449/449 [==============================] - 15s 32ms/step - loss: 0.3279 - accuracy: 0.8905 - val_loss: 1.7858 - val_accuracy: 0.5720\n",
      "Epoch 162/200\n",
      "449/449 [==============================] - 15s 33ms/step - loss: 0.3204 - accuracy: 0.8910 - val_loss: 1.8500 - val_accuracy: 0.5748\n",
      "Epoch 163/200\n",
      "449/449 [==============================] - 14s 31ms/step - loss: 0.3113 - accuracy: 0.8942 - val_loss: 1.8700 - val_accuracy: 0.5595\n",
      "Epoch 164/200\n",
      "449/449 [==============================] - 15s 33ms/step - loss: 0.3191 - accuracy: 0.8912 - val_loss: 1.8977 - val_accuracy: 0.5659\n",
      "Epoch 165/200\n",
      "449/449 [==============================] - 16s 35ms/step - loss: 0.3184 - accuracy: 0.8926 - val_loss: 1.9442 - val_accuracy: 0.5573\n",
      "Epoch 166/200\n",
      "449/449 [==============================] - 18s 41ms/step - loss: 0.3130 - accuracy: 0.8931 - val_loss: 1.9790 - val_accuracy: 0.5595\n",
      "Epoch 167/200\n",
      "449/449 [==============================] - 16s 36ms/step - loss: 0.3296 - accuracy: 0.8911 - val_loss: 1.7978 - val_accuracy: 0.5642\n",
      "Epoch 168/200\n",
      "449/449 [==============================] - 18s 39ms/step - loss: 0.3175 - accuracy: 0.8912 - val_loss: 1.9161 - val_accuracy: 0.5634\n",
      "Epoch 169/200\n",
      "449/449 [==============================] - 13s 29ms/step - loss: 0.3294 - accuracy: 0.8878 - val_loss: 2.0091 - val_accuracy: 0.5637\n",
      "Epoch 170/200\n",
      "449/449 [==============================] - 18s 41ms/step - loss: 0.3176 - accuracy: 0.8955 - val_loss: 1.8928 - val_accuracy: 0.5581\n",
      "Epoch 171/200\n",
      "449/449 [==============================] - 18s 40ms/step - loss: 0.3166 - accuracy: 0.8933 - val_loss: 1.8710 - val_accuracy: 0.5645\n",
      "Epoch 172/200\n",
      "449/449 [==============================] - 18s 40ms/step - loss: 0.3204 - accuracy: 0.8924 - val_loss: 1.9588 - val_accuracy: 0.5667\n",
      "Epoch 173/200\n",
      "449/449 [==============================] - 18s 40ms/step - loss: 0.3089 - accuracy: 0.8947 - val_loss: 1.8691 - val_accuracy: 0.5726\n",
      "Epoch 174/200\n",
      "449/449 [==============================] - 13s 30ms/step - loss: 0.3190 - accuracy: 0.8937 - val_loss: 1.8968 - val_accuracy: 0.5684\n",
      "Epoch 175/200\n",
      "449/449 [==============================] - 15s 34ms/step - loss: 0.3145 - accuracy: 0.8942 - val_loss: 1.8512 - val_accuracy: 0.5606\n",
      "Epoch 176/200\n",
      "449/449 [==============================] - 23s 51ms/step - loss: 0.3159 - accuracy: 0.8933 - val_loss: 1.8720 - val_accuracy: 0.5676\n",
      "Epoch 177/200\n",
      "449/449 [==============================] - 14s 30ms/step - loss: 0.2979 - accuracy: 0.8996 - val_loss: 1.8870 - val_accuracy: 0.5648\n",
      "Epoch 178/200\n",
      "449/449 [==============================] - 17s 39ms/step - loss: 0.3107 - accuracy: 0.8939 - val_loss: 1.8576 - val_accuracy: 0.5754\n",
      "Epoch 179/200\n",
      "449/449 [==============================] - 21s 47ms/step - loss: 0.3077 - accuracy: 0.8971 - val_loss: 1.9431 - val_accuracy: 0.5717\n",
      "Epoch 180/200\n",
      "449/449 [==============================] - 23s 52ms/step - loss: 0.3202 - accuracy: 0.8925 - val_loss: 1.8493 - val_accuracy: 0.5731\n",
      "Epoch 181/200\n",
      "449/449 [==============================] - 24s 52ms/step - loss: 0.3023 - accuracy: 0.8991 - val_loss: 1.8662 - val_accuracy: 0.5656\n",
      "Epoch 182/200\n",
      "449/449 [==============================] - 24s 53ms/step - loss: 0.3023 - accuracy: 0.8998 - val_loss: 1.9698 - val_accuracy: 0.5564\n",
      "Epoch 183/200\n",
      "449/449 [==============================] - 24s 54ms/step - loss: 0.2950 - accuracy: 0.9014 - val_loss: 1.9720 - val_accuracy: 0.5642\n",
      "Epoch 184/200\n",
      "449/449 [==============================] - 13s 29ms/step - loss: 0.3090 - accuracy: 0.8977 - val_loss: 1.9434 - val_accuracy: 0.5634\n",
      "Epoch 185/200\n",
      "449/449 [==============================] - 13s 29ms/step - loss: 0.3050 - accuracy: 0.8980 - val_loss: 1.8688 - val_accuracy: 0.5564\n",
      "Epoch 186/200\n",
      "449/449 [==============================] - 13s 28ms/step - loss: 0.3146 - accuracy: 0.8936 - val_loss: 1.9199 - val_accuracy: 0.5645\n",
      "Epoch 187/200\n",
      "449/449 [==============================] - 13s 29ms/step - loss: 0.3091 - accuracy: 0.8963 - val_loss: 1.9178 - val_accuracy: 0.5678\n",
      "Epoch 188/200\n",
      "449/449 [==============================] - 13s 29ms/step - loss: 0.2927 - accuracy: 0.9009 - val_loss: 2.0181 - val_accuracy: 0.5717\n",
      "Epoch 189/200\n",
      "449/449 [==============================] - 13s 30ms/step - loss: 0.3104 - accuracy: 0.8980 - val_loss: 1.8689 - val_accuracy: 0.5653\n",
      "Epoch 190/200\n",
      "449/449 [==============================] - 13s 30ms/step - loss: 0.2996 - accuracy: 0.9005 - val_loss: 1.8634 - val_accuracy: 0.5589\n",
      "Epoch 191/200\n",
      "449/449 [==============================] - 14s 30ms/step - loss: 0.2985 - accuracy: 0.8988 - val_loss: 1.8518 - val_accuracy: 0.5639\n",
      "Epoch 192/200\n",
      "449/449 [==============================] - 10s 23ms/step - loss: 0.3007 - accuracy: 0.8997 - val_loss: 1.9456 - val_accuracy: 0.5528\n",
      "Epoch 193/200\n",
      "449/449 [==============================] - 11s 24ms/step - loss: 0.2939 - accuracy: 0.9029 - val_loss: 1.9346 - val_accuracy: 0.5598\n",
      "Epoch 194/200\n",
      "449/449 [==============================] - 11s 25ms/step - loss: 0.3053 - accuracy: 0.8985 - val_loss: 1.9556 - val_accuracy: 0.5587\n",
      "Epoch 195/200\n",
      "449/449 [==============================] - 11s 25ms/step - loss: 0.3021 - accuracy: 0.9001 - val_loss: 1.8653 - val_accuracy: 0.5653\n",
      "Epoch 196/200\n",
      "449/449 [==============================] - 11s 26ms/step - loss: 0.3035 - accuracy: 0.8978 - val_loss: 1.9713 - val_accuracy: 0.5673\n",
      "Epoch 197/200\n",
      "449/449 [==============================] - 11s 25ms/step - loss: 0.2995 - accuracy: 0.9014 - val_loss: 1.9328 - val_accuracy: 0.5648\n",
      "Epoch 198/200\n",
      "449/449 [==============================] - 12s 26ms/step - loss: 0.2939 - accuracy: 0.9035 - val_loss: 1.8560 - val_accuracy: 0.5695\n",
      "Epoch 199/200\n",
      "449/449 [==============================] - 12s 27ms/step - loss: 0.2960 - accuracy: 0.9029 - val_loss: 1.7759 - val_accuracy: 0.5695\n",
      "Epoch 200/200\n",
      "449/449 [==============================] - 20s 46ms/step - loss: 0.2914 - accuracy: 0.9035 - val_loss: 1.8374 - val_accuracy: 0.5642\n"
     ]
    }
   ],
   "source": [
    "num_features = 64\n",
    "num_labels = 7\n",
    "batch_size = 64\n",
    "epochs = 200\n",
    "width, height = 48, 48\n",
    "\n",
    "\n",
    "X_train = np.array(X_train,'float32')\n",
    "train_y = np.array(train_y,'float32')\n",
    "X_test = np.array(X_test,'float32')\n",
    "test_y = np.array(test_y,'float32')\n",
    "\n",
    "train_y=np_utils.to_categorical(train_y, num_classes=num_labels)\n",
    "test_y=np_utils.to_categorical(test_y, num_classes=num_labels)\n",
    "\n",
    "#cannot produce\n",
    "#normalizing data between oand 1\n",
    "X_train -= np.mean(X_train, axis=0)\n",
    "X_train /= np.std(X_train, axis=0)\n",
    "\n",
    "X_test -= np.mean(X_test, axis=0)\n",
    "X_test /= np.std(X_test, axis=0)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 48, 48, 1)\n",
    "\n",
    "X_test = X_test.reshape(X_test.shape[0], 48, 48, 1)\n",
    "\n",
    "# print(f\"shape:{X_train.shape}\")\n",
    "##designing the cnn\n",
    "#1st convolution layer\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(X_train.shape[1:])))\n",
    "model.add(Conv2D(64,kernel_size= (3, 3), activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#2nd convolution layer\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#3rd convolution layer\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "#fully connected neural networks\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(num_labels, activation='softmax'))\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "#Compliling the model\n",
    "model.compile(loss=categorical_crossentropy,\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#Training the model\n",
    "model.fit(X_train, train_y,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, test_y),\n",
    "          shuffle=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the  model to  use it later on\n",
    "fer_json = model.to_json()\n",
    "with open(\"fer.json\", \"w\") as json_file:\n",
    "    json_file.write(fer_json)\n",
    "model.save_weights(\"fer.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
